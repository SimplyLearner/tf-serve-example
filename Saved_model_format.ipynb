{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9302d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('xception_v4_large_08_0.894.h5')\n",
    "tf.saved_model.save(model, 'clothing-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f5204",
   "metadata": {},
   "source": [
    "To be able to use this model later, we need to know a few things:\n",
    "\n",
    "- The name of the model signature. The model signature describes the model’s inputs and outputs. You can read more about model signatures here: https://www.tensorflow.org/tfx/serving/signature_defs.\n",
    "- The name of the input layer.\n",
    "- The name of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd846fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 20:40:07.495392: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-28 20:40:07.495455: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_8'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 299, 299, 3)\n",
      "        name: serving_default_input_8:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_7'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_8: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_8')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir clothing-model --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe7c3e",
   "metadata": {},
   "source": [
    "In this output, we’re interested in three things:\n",
    "\n",
    "- The signature definition (signature_def) of the model. In this case, it’s serving_ default.\n",
    "- The input (input_8). The name of the input of the model.\n",
    "- The output (dense_7). The name of the output layer of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f8615",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "docker run -it --rm \\\n",
    "    -p 8500:8500 \\\n",
    "    -v \"C:\\Users\\navan\\PGP\\deploy-tf\\clothing-model:/models/clothing-model/1\" \\\n",
    "    -e MODEL_NAME=clothing-model \\\n",
    "    tensorflow/serving:2.3.0\n",
    "\n",
    "```\n",
    "\n",
    "When running it, we use three parameters:\n",
    "\n",
    "* -p: To map port 8500 on the host machine (the computer where we run Docker) to port 8500 inside the container \n",
    "* -v: To put the model files inside the Docker image . The model is put in /models/clothing-model/1, where clothing-model is the name of the model and 1 is the version.\n",
    "* -e: To set the MODEL_NAME variable to clothing-model, which is the directory name from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6678ff",
   "metadata": {},
   "source": [
    "## Invoking TfServing from Model\n",
    "\n",
    "TF Serving uses gRPC—a special protocol designed for high-performance communication. This protocol relies on protobuf, a format for effective data transfer. Unlike JSON, it’s binary, which makes the requests significantly more compact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1034d",
   "metadata": {},
   "source": [
    "### Installation steps are:\n",
    "\n",
    "```\n",
    "pip install grpcio==1.32.0\n",
    "pip install tensorflow-serving-api==2.3.0\n",
    "pip install keras_image_helper==0.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5caa0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc  # for communicating with tf serving\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d836f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost:8500\"\n",
    "channel = grpc.insecure_channel(host)\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce753e1",
   "metadata": {},
   "source": [
    "#### Reference:\n",
    "\n",
    "https://pypi.org/project/keras-image-helper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c294a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor\n",
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b90ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53214152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ec7d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4f0f2",
   "metadata": {},
   "source": [
    "For gRPC, we need to convert it to protobuf. TensorFlow has a special function for that: `tf.make_tensor_proto`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b0678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_protobuf(data):\n",
    "    return tf.make_tensor_proto(data,shape = data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7177dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = \"clothing-model\"\n",
    "request.model_spec.signature_name = \"serving_default\"\n",
    "request.inputs[\"input_8\"].CopyFrom(np_to_protobuf(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f1b42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_result = stub.Predict(request, timeout = 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b5a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pb_result.outputs['dense_7'].float_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "290e5d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.8682907819747925, -4.761244773864746, -2.316983461380005, -1.062570333480835, 9.887161254882812, -2.812433958053589, -3.666283130645752, 3.200361728668213, -2.6023383140563965, -4.835046768188477]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84eea2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    " \n",
    "result = {c: p for c, p in zip(labels, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44ca21a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8682907819747925,\n",
       " 'hat': -4.761244773864746,\n",
       " 'longsleeve': -2.316983461380005,\n",
       " 'outwear': -1.062570333480835,\n",
       " 'pants': 9.887161254882812,\n",
       " 'shirt': -2.812433958053589,\n",
       " 'shoes': -3.666283130645752,\n",
       " 'shorts': 3.200361728668213,\n",
       " 'skirt': -2.6023383140563965,\n",
       " 't-shirt': -4.835046768188477}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74623b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
